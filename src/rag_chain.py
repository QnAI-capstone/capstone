import openai
from src.config import OPENAI_API_KEY
from src.embedder import get_embedding
from src.vectorstore import query_documents

openai.api_key = OPENAI_API_KEY

def answer_query(query: str, top_k: int = 3) -> str:
    query_embedding = get_embedding(query)
    if query_embedding is None:
        return "âŒ ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨"

    search_result = query_documents(query_embedding, top_k=top_k)
    contexts = search_result.get("documents", [[]])[0]
    metadatas = search_result.get("metadatas", [[]])[0]

    # ì»¨í…ìŠ¤íŠ¸ + ì¶œì²˜ ì •ë³´
    context_text = ""
    for i, (text, meta) in enumerate(zip(contexts, metadatas), start=1):
        page = meta.get("page", "?")
        src = meta.get("source", "?")
        context_text += f"\n---\nğŸ“„ Doc {i} (Page {page}, Source: {src})\n{text}\n"

    # GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
    prompt = f"""
ë‹¹ì‹ ì€ PDF ë¬¸ì„œ ê¸°ë°˜ì˜ ì§€ì‹ ì±—ë´‡ì…ë‹ˆë‹¤.
ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ë¬¸ì„œ ë‚´ìš©:
{context_text}
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4" ì‚¬ìš© ê°€ëŠ¥
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âŒ GPT ì‘ë‹µ ì‹¤íŒ¨: {e}"
